import os
from pathlib import Path
from itertools import product
import numpy as np
import matplotlib.pyplot as plt
from pyproj import Transformer  # convert geographic to Cartesian coordinates: https://stackoverflow.com/a/69604627
import utm

from load_map import load_map, extract_waypoints
from openai_models import get_embed
from utils import load_from_file


KNOWN_RELATIONS = [
    "left", "left of", "to the left of", "right", "right of", "to the right of",
    "in front of", "opposite", "opposite to", "behind", "behind of", "at the rear of",
    "near", "next", "next to", "adjacent to", "close", "close to", "at", "by", "between",
    "north of", "south of", "east of", "west of", "northeast of", "northwest of", "southeast of", "southwest of"
]
MAX_RANGE = 25.0  # assume target within this radius of the anchor
RANGE_TO_ANCHOR = 2.0  # indicates the offset to compute a target location for SREs without a target


def plot_landmarks(landmarks=None):
    """
    Plot landmarks in the shared world space local to the Spot's map
    """
    plt.figure()

    if landmarks:
        plt.scatter(x=[landmarks[L]["x"] for L in landmarks], y=[landmarks[L]["y"] for L in landmarks], c="green", label="landmarks")
        for L in landmarks:
            if "osm_name" not in landmarks[L] and L != "robot":
                plt.text(landmarks[L]["x"], landmarks[L]["y"], L)

    plt.scatter(x=landmarks["robot"]["x"],
                y=landmarks["robot"]["y"], c="orange", label="robot")
    plt.text(landmarks["robot"]["x"],
             landmarks["robot"]["y"], "robot")

    plt.title(f"Landmark Map")
    plt.legend()
    # plt.axis("square")
    plt.show(block=True)
    # plt.savefig("temp.png")


def rotate(vec, angle):
    # https://motion.cs.illinois.edu/RoboticSystems/CoordinateTransformations.html
    mat_rot = np.array([[np.cos(angle), -np.sin(angle)], [np.sin(angle), np.cos(angle)]])
    return np.dot(mat_rot, vec)


def align_coordinates(graph_dpath, waypoints, osm_landmarks, coord_alignment, crs):
    # rotation and translation to align Spot's frame to world Cartesian frame (default: 0, not needed if no robot graph)
    rotation, translation = 0, 0

    if coord_alignment:
        # If use Spot graph, alignment landmark value is not None, then compute rotation and translation for alignment
        print(" >> Computing alignment from robot to world frame...")
        known_landmark_1 = np.array(crs.transform(coord_alignment[0]["long"], coord_alignment[0]["lat"], 0, radians=False)[:-1])
        known_landmark_2 = np.array(crs.transform(coord_alignment[1]["long"], coord_alignment[1]["lat"], 0, radians=False)[:-1])

        known_waypoint_1 = np.array([waypoints[coord_alignment[0]["waypoint"]]["position"]["x"],
                                     waypoints[coord_alignment[0]["waypoint"]]["position"]["y"]])
        known_waypoint_2 = np.array([waypoints[coord_alignment[1]["waypoint"]]["position"]["x"],
                                     waypoints[coord_alignment[1]["waypoint"]]["position"]["y"]])

        # Use the vector from known landmarks to compute rotation
        vec_lmk_1_to_2 = known_landmark_2 - known_landmark_1
        vec_wp_1_to_2 = known_waypoint_2 - known_waypoint_1

        # Compute the rotation between the known landmark and waypoint
        dir_world = np.arctan2(vec_lmk_1_to_2[1], vec_lmk_1_to_2[0])  # i.e., world coordinate
        dir_robot = np.arctan2(vec_wp_1_to_2[1], vec_wp_1_to_2[0])  # i.e., spot coordinate

        rotation = dir_world - dir_robot

    landmarks = {}

    if graph_dpath and waypoints:
        # Each image is named after the Spot waypoint name (auto-generated by GraphNav)
        waypoint_ids = [Path(image_fpath).stem for image_fpath in os.listdir(os.path.join(graph_dpath, "images"))]

        for wid, wp_desc in waypoints.items():
            # NOTE: all landmarks are either one of the following:
            #   1. landmarks whose waypoints were manually created by GraphNav (i.e., they have images)
            #   2. waypoint_0: robot start location when using GraphNav
            is_landmark = True if wid in waypoint_ids or wp_desc["name"] == "waypoint_0" else False

            if is_landmark:
                cartesian_coords = np.array([wp_desc["position"]["x"], wp_desc["position"]["y"]])

                # Align the Spot's cartesian coordinates to the world frame:
                cartesian_coords = rotate(cartesian_coords, rotation)

                if coord_alignment:
                    # Use the newly rotated point to figure out the translation
                    if wid == coord_alignment[0]["waypoint"]:
                        known_waypoint_1 = cartesian_coords
                    elif wid == coord_alignment[1]["waypoint"]:
                        known_waypoint_2 = cartesian_coords

                lmk_id = "robot" if wp_desc["name"] == "waypoint_0" else wid
                landmarks[lmk_id] = {"x": cartesian_coords[0], "y": cartesian_coords[1]}

        if coord_alignment:
            # Compute translation to align the known landmark from world to Spot space AFTER rotation
            translation = ((known_waypoint_1 - known_landmark_1) + (known_waypoint_2 - known_landmark_2)) / 2.0
    else:
        # This means we are only working with OSM landmarks
        print(" >> WARNING: not using Spot graph")

    # Process then add OSM landmarks if provided
    if osm_landmarks:
        for lmk, lmk_desc in osm_landmarks.items():
            lmk_id = lmk.lower().replace(' ', '_')

            if "wid" in lmk_desc:
                # OSM landmarks visited by Spot GraphNav have waypoint ID associated with it, then just Spot graph coorindate
                wid = lmk_desc["wid"]
                lmk_cartesian = np.array([landmarks[wid]["x"], landmarks[wid]["y"]])
                landmarks[wid]["osm_name"] = lmk_id
            else:
                # Convert landmark location to Cartesian coordinate then add computed translation
                lmk_cartesian = np.array(crs.transform(lmk_desc["long"], lmk_desc["lat"], 0, radians=False)[:-1])
                lmk_cartesian += translation

            landmarks[lmk_id] = {"x": lmk_cartesian[0], "y": lmk_cartesian[1]}

    return landmarks


def create_waypoints(obj_fpath, crs):
    """
    Create waypoints of objects similar to that created by Spot GraphNav.
    """
    objects = load_from_file(obj_fpath)

    # Set the origin of Cartesian coordinates to the location of the robot
    robot = None
    if "waypoint_0" in objects:
        robot = objects["waypoint_0"]
    else:
        print(" >> ERROR: missing robot coordinates. Check obj_fpath file")
        exit()

    if "lat" in list(objects.values())[0]:
        # Convert locations of objects from geographic to Cartesian coordinates if not provided as Cartesian cooridinates.
        if not crs:
            _, _, zone, _ = utm.from_latlon(robot["lat"], robot["long"])
            crs = Transformer.from_crs(crs_from="+proj=latlong +ellps=WGS84 +datum=WGS84",
                                       crs_to=f"+proj=utm +ellps=WGS84 +datum=WGS84 +south +units=m +zone={zone}")

        # NOTE: a 2D map actually is projected to the X-Z Cartesian plane, NOT X-Y
        # thus we only take the x and z coordinates, where the z will be used as Spot's y-axis
        for loc in objects.values():
            loc["x"], loc["y"] = crs.transform(loc["long"], loc["lat"], 0, radians=False)[:-1]

    # Convert to same data structure output by Spot GraphNav
    waypoints = {obj: {"name": obj, "position": {"x": loc["x"], "y": loc["y"]}} for obj, loc in objects.items()}

    return waypoints, crs


def load_lmks(graph_dpath=None, osm_fpath=None):
    """
    Load landmarks from OSM or Spot graph or both then convert their locations to Cartesian coordinates.
    """
    # Load waypoints from provided directory path to Spot graph if exists
    waypoints, transformer = None, None
    try:
        graph, _, _, _, _, _ = load_map(graph_dpath)
    except Exception:
        print(" >> WARNING: no Spot graph file found in provided directory path")
        waypoints, transformer = create_waypoints(os.path.join(graph_dpath, "obj_locs.json"), crs=None)
    else:
        # Get important details from Spot graph and create a dict instead of using their data structure
        waypoints = extract_waypoints(graph)

    # Load text description of OSM landmarks
    osm_landmarks = []
    if os.path.isfile(osm_fpath):
        osm_landmarks = load_from_file(osm_fpath)

        # Use geographic coordinates of first landmark to get a zone number for UTM conversion
        lmk_desc = list(osm_landmarks.values())[0]
        _, _, zone, _ = utm.from_latlon(lmk_desc["lat"], lmk_desc["long"])
        transformer = Transformer.from_crs(crs_from="+proj=latlong +ellps=WGS84 +datum=WGS84",
                                           crs_to=f"+proj=utm +ellps=WGS84 +datum=WGS84 +south +units=m +zone={zone}")
    else:
        print(" >> WARNING: no OSM landmarks loaded")

    alignment_lmks = []
    alignment_fpath = os.path.join(graph_dpath, "alignment.json")  # contain Spot graph waypoints in both geographic and Cartesian coordinates
    if os.path.isfile(alignment_fpath):
        alignment_lmks = load_from_file(alignment_fpath)

    # Put Spot waypoints and OSM landmarks in Cartesian coordinates
    landmarks = align_coordinates(graph_dpath, waypoints, osm_landmarks, alignment_lmks, transformer)

    # Visualize landmarks
    plot_landmarks(landmarks)

    return landmarks


def sort_combs(lmk_grounds):
    """
    Sort all combinations of target and anchor landmarks by their joint cosine similarity scores.
    """
    combs_sorted = []

    for comb in list(product(*lmk_grounds)):  # Cartesian product of lists of target and anchor landmarks
        joint_score = 1
        target, anchor = [], []

        for idx, score_lmk in enumerate(comb):
            joint_score *= score_lmk[0]

            # Get target or anchor landmark name of the combination
            if idx == 0:  # target landmark is always the first in a combination
                target.append(score_lmk[1])
            else:  # SRE with 0, 1 or 2 target landmarks
                anchor.append(score_lmk[1])

        combs_sorted.append({"score": joint_score, "target": target, "anchor": anchor})

    combs_sorted.sort(key=lambda comb: comb["score"], reverse=True)
    return combs_sorted


def find_match_rel(rel_unseen):
    """
    Use cosine similatiry between text embeddings to find best matching known spatil relation to the unseen input
    """
    closest_rel, closest_rel_embed = None, None
    unseen_rel_embed = get_embed(rel_unseen)

    for known_rel in KNOWN_RELATIONS:
        candidate_embed = get_embed(known_rel)

        if not closest_rel:
            closest_rel = known_rel
            closest_rel_embed = candidate_embed
        else:
            current_score = np.dot(unseen_rel_embed, closest_rel_embed)
            new_rel_score = np.dot(unseen_rel_embed, candidate_embed)

            if current_score < new_rel_score:
                closest_rel = known_rel
                closest_rel_embed = candidate_embed

    return closest_rel


def compute_area(landmarks, spatial_rel, anchor, do_360_search=False, plot=False):
    robot = landmarks["robot"]

    # NOTE: we want to draw a vector from the anchor"s perspective to the robot!
    # -- this gives us a normal vector pointing outside of the anchor object
    list_ranges = []

    # -- compute vector between robot"s position and anchor position and get its direction:
    vector_a2r = [robot["x"] - anchor["x"],
                  robot["y"] - anchor["y"]]

    # -- draw a unit vector and multiply it by 10 to get the max distance to consider:
    unit_vec_a2r = np.array(vector_a2r) / np.linalg.norm(vector_a2r)

    # NOTE: mean angle of 0 if we get the spatial relation "in front of" or "opposite"
    mean_angle = 0
    if spatial_rel in ["left", "left of", "to the left of"]:
        # -- if we want something to the left, we need to go in positive 90 degrees:
        mean_angle = -90
    elif spatial_rel in ["right", "right of", "to the right of"]:
        # -- if we want something to the right, we need to go in negative 90 degrees:
        mean_angle = 90
    elif spatial_rel in ["behind", "at the rear of", "behind of"]:
        # -- if we want something to the right, we need to tn 180 degees:
        mean_angle = 180
    elif spatial_rel in ["north of", "south of", "east of", "west of", "northeast of", "northwest of", "southeast of", "southwest of"]:
        # -- we need to find the difference between each cardinal direction and the current anchor-to-robot vector
        #       to figure out how much we need to rotate it by:
        if spatial_rel in ["north", "north of"]:
            mean_angle = np.rad2deg(np.arctan2(1, 0) - np.arctan2(unit_vec_a2r[1], unit_vec_a2r[0]))
        elif spatial_rel in ["south", "south of"]:
            mean_angle = np.rad2deg(np.arctan2(-1, 0) - np.arctan2(unit_vec_a2r[1], unit_vec_a2r[0]))
        elif spatial_rel in ["east", "east of"]:
            mean_angle = np.rad2deg(np.arctan2(0, 1) - np.arctan2(unit_vec_a2r[1], unit_vec_a2r[0]))
        elif spatial_rel in ["west", "west of"]:
            mean_angle = np.rad2deg(np.arctan2(0, -1) - np.arctan2(unit_vec_a2r[1], unit_vec_a2r[0]))
        elif spatial_rel in ["northeast", "northeast of"]:
            mean_angle = np.rad2deg(np.arctan2(1, 1) - np.arctan2(unit_vec_a2r[1], unit_vec_a2r[0]))
        elif spatial_rel in ["northwest", "northwest of"]:
            mean_angle = np.rad2deg(np.arctan2(1, -1) - np.arctan2(unit_vec_a2r[1], unit_vec_a2r[0]))
        elif spatial_rel in ["southeast", "southeast of"]:
            mean_angle = np.rad2deg(np.arctan2(-1, 1) - np.arctan2(unit_vec_a2r[1], unit_vec_a2r[0]))
        elif spatial_rel in ["southwest", "southwest of"]:
            mean_angle = np.rad2deg(np.arctan2(-1, -1) - np.arctan2(unit_vec_a2r[1], unit_vec_a2r[0]))

        # NOTE: since cardinal directions are absolute, we should not do any 360-sweep:
        do_360_search = False

    # -- this dictates how wide of a field-of-view we attribute to the robot:
    field_of_view = 180

    # -- checking for sweep condition: this means we will consider different normal vectors
    #       representing the "front" of the object:
    rot_a2r = [0]
    if spatial_rel in ["near", "near to", "next", "next to", "adjacent to", "close to", "at", "close", "by"] or do_360_search:
        rot_a2r += [x * field_of_view for x in range(1, int(360 / field_of_view))]

    # print(rot_a2r)
    for x in rot_a2r:
        # -- rotate the anchor"s frame of reference by some angle x:
        a2r_vector = rotate(unit_vec_a2r, np.deg2rad(x))

        # -- compute the mean vector as well as vectors representing min and max proximity range:
        a2r_mean = rotate(a2r_vector, np.deg2rad(mean_angle))
        a2r_min_range = rotate(a2r_vector, np.deg2rad(mean_angle-(field_of_view/2)))
        a2r_max_range = rotate(a2r_vector, np.deg2rad(mean_angle+(field_of_view/2)))

        # -- append the vectors to the list of evaluated ranges:
        list_ranges.append({"mean": a2r_mean, "min": a2r_min_range, "max": a2r_max_range})

    if plot:
        plt.figure()

        # -- plotting the robot"s position as well as the anchor point:
        plt.scatter(x=[robot["x"]],
                    y=[robot["y"]], marker="o", color="yellow", label="robot")
        plt.scatter(x=[anchor["x"]],
                    y=[anchor["y"]], marker="o", color="orange", label="anchor")
        plt.text(anchor["x"], anchor["y"], s=anchor["name"])

        # -- plotting the normal vector from the robot to the anchor:
        plt.plot([robot["x"], anchor["x"]],
                 [robot["y"], anchor["y"]], color="black")
        plt.arrow(x=robot["x"], y=robot["y"], dx=-vector_a2r[0]/2.0, dy=-vector_a2r[1]/2.0, shape="full",
                    width=0.01, head_width=0.1, color="black", label="normal")

        for r in range(len(list_ranges)):
            mean_pose = [(list_ranges[r]["mean"][0] * MAX_RANGE) + anchor["x"],
                            (list_ranges[r]["mean"][1] * MAX_RANGE) + anchor["y"]]
            plt.scatter(x=[mean_pose[0]], y=[mean_pose[1]],
                        c="g", marker="o", label=f"mean_{r}")

            min_pose = [(list_ranges[r]["min"][0] * MAX_RANGE) + anchor["x"],
                        (list_ranges[r]["min"][1] * MAX_RANGE) + anchor["y"]]
            plt.scatter(x=[min_pose[0]], y=[min_pose[1]],
                        c="r", marker="x", label=f"min_{r}")

            max_pose = [(list_ranges[r]["max"][0] * MAX_RANGE) + anchor["x"],
                        (list_ranges[r]["max"][1] * MAX_RANGE) + anchor["y"]]
            plt.scatter(x=[max_pose[0]], y=[max_pose[1]],
                        c="b", marker="x", label=f"max_{r}")

            plt.plot([anchor["x"], mean_pose[0]],
                     [anchor["y"], mean_pose[1]], linestyle="dashed", c="g")
            plt.plot([anchor["x"], min_pose[0]],
                     [anchor["y"], min_pose[1]], linestyle="dotted", c="r")
            plt.plot([anchor["x"], max_pose[0]],
                     [anchor["y"], max_pose[1]], linestyle="dotted", c="b")

        plt.title(f"Evaluated range for spatial relation: {spatial_rel}")
        plt.legend()
        plt.axis("square")
        plt.show(block=False)

    return list_ranges


def get_target_pos(landmarks, spatial_rel, anchor_candidate, sre=None, plot=False):
    """
    Spatial referring expression: cardinal directions; maybe left, right?
    """
    # -- this means that we have no target landmark: we solely want to find a position relative to a given anchor
    try:
        anchor = landmarks[anchor_candidate]
    except KeyError:
        return None

    robot = landmarks["robot"]

    # -- get the list of valid ranges (potentially only one) for an anchoring landmark:
    list_ranges = compute_area(spatial_rel, anchor)

    # -- we want to find the closest point from the robot to the anchoring landmark that satisfies the given spatial relation:
    closest_position = 0

    for R in range(len(list_ranges)):

        cur_min_pos = {"x": (list_ranges[R]["mean"][0] * RANGE_TO_ANCHOR) + anchor["x"],
                       "y": (list_ranges[R]["mean"][1] * RANGE_TO_ANCHOR) + anchor["y"]}
        cur_min_dist = np.linalg.norm(np.array([cur_min_pos["x"], cur_min_pos["y"]]) - np.array([robot["x"], robot["y"]]))

        new_min_pos = {"x": (list_ranges[closest_position]["mean"][0] * RANGE_TO_ANCHOR) + anchor["x"],
                       "y": (list_ranges[closest_position]["mean"][1] * RANGE_TO_ANCHOR) + anchor["y"]}
        new_min_dist = np.linalg.norm(np.array([new_min_pos["x"], new_min_pos["y"]]) - np.array([robot["x"], robot["y"]]))

        if cur_min_dist > new_min_dist:
            new_min_pos = R

    # -- select the index that was found to be closest to the robot:
    R = list_ranges[closest_position]

    # -- use the mean vector to find a point that is within RANGE_TO_ANCHOR (2m) of the anchor:
    new_robot_pos = {"x": (R["mean"][0] * RANGE_TO_ANCHOR) + anchor["x"],
                     "y": (R["mean"][1] * RANGE_TO_ANCHOR) + anchor["y"]}

    if plot:
        plt.figure()

        plt.scatter(x=[robot["x"]], y=[robot["y"]], marker="o", label="robot")
        plt.scatter(x=[new_robot_pos["x"]], y=[new_robot_pos["y"]], marker="x", c="g", s=15, label="new robot pose")

        # -- plot all anchors and targets provided to the function:
        for A in landmarks:
            plt.scatter(x=landmarks[A]["x"],
                        y=landmarks[A]["y"],
                        marker="o", c="darkorange", label=f"anchor: {A}")
            plt.text(landmarks[A]["x"], landmarks[A]["y"], A)

        # -- plot the range as well for visualization:
        plt.plot([anchor["x"], (R["min"][0] * RANGE_TO_ANCHOR) + anchor["x"]],
                 [anchor["y"], (R["min"][1] * RANGE_TO_ANCHOR) + anchor["y"]],
                 linestyle="dotted", c="r")
        plt.plot([anchor["x"], (R["max"][0] * RANGE_TO_ANCHOR) + anchor["x"]],
                 [anchor["y"], (R["max"][1] * RANGE_TO_ANCHOR) + anchor["y"]],
                 linestyle="dotted", c="b")

        plt.title(f"Computed Target Position: {sre}" if sre else f"Computed Target Position: {spatial_rel}")
        plt.axis("square")
        plt.legend()
        plt.show(block=False)

    return new_robot_pos


def eval_spatial_pred(landmarks, spatial_rel, target_candidate, anchor_candidates, sre=None, plot=False):
    # -- in this case, we will be given a list of target objects or entities:
    target = landmarks[target_candidate]

    # -- we cannot evaluate a landmark against itself, so we need to check if any
    #       anchor candidates are equal to the target candidate:
    if target_candidate in anchor_candidates:
        return False

    for A in anchor_candidates:
        # -- we will check if any anchor has the same (x,y) coordinates as the target:
        if target["x"] == landmarks[A]["x"] and target["y"] == landmarks[A]["y"]:
            return False

    # -- robot is listed as a landmark:
    robot = landmarks["robot"]

    if spatial_rel not in ["between"]:

        try:
            anchor = landmarks[anchor_candidates[0]]
        except KeyError:
            return False

        anchor["name"] = anchor_candidates[0]

        list_ranges = compute_area(landmarks, spatial_rel, anchor, plot)

        is_valid = False

        for R in list_ranges:
            v_tgt = np.array([target["x"] - anchor["x"], target["y"] - anchor["y"]])
            v_min = np.array([R["min"][0], R["min"][1]])
            v_max = np.array([R["max"][0], R["max"][1]])

            # -- checking if the target vector lies between the min and max vectors
            #       Source: https://stackoverflow.com/a/17497339
            is_within_vectors = bool(np.cross(v_max,v_tgt) * np.cross(v_max,v_min) >= 0) and bool(np.cross(v_min,v_tgt) * np.cross(v_min,v_max) >= 0)

            a2t_distance = np.linalg.norm(np.array([target["x"], target["y"]]) - np.array([anchor["x"], anchor["y"]]))

            if is_within_vectors and a2t_distance <= MAX_RANGE:
                print(f"    - VALID LANDMARKS:\ttarget:{target_candidate}\tanchor:{anchor_candidates[0]}")
                is_valid = True
                break

        if is_valid:

            if plot:
                # -- plot the computed range:
                plt.figure()
                plt.title(f"Final Grounding: {sre}\n(Target:{target_candidate}, Anchor:{anchor_candidates})")
                plt.scatter(x=[robot["x"]], y=[robot["y"]], marker="o", color="yellow", label="robot")
                plt.scatter(x=[anchor["x"]], y=[anchor["y"]], marker="o", color="orange", label="anchor")
                plt.scatter(x=[target["x"]], y=[target["y"]], marker="o", color="green", label="target")
                plt.plot([robot["x"], anchor["x"]], [robot["y"], anchor["y"]], linestyle="dotted", c="k", label="normal")

                plt.text(anchor["x"], anchor["y"], s=anchor_candidates[0])
                plt.text(target["x"], target["y"], s=target_candidate)

                for R in range(len(list_ranges)):
                    mean_pose = np.array([(list_ranges[R]["mean"][0] * MAX_RANGE) + anchor["x"],
                                    (list_ranges[R]["mean"][1] * MAX_RANGE) + anchor["y"]])
                    # plt.scatter(x=[mean_pose[0]], y=[mean_pose[1]], c="g", marker="o", label="mean")

                    min_pose = np.array([(list_ranges[R]["min"][0] * MAX_RANGE) + anchor["x"],
                                (list_ranges[R]["min"][1] * MAX_RANGE) + anchor["y"]])
                    # plt.scatter(x=[min_pose[0]], y=[min_pose[1]], c="r", marker="x", label="min")

                    max_pose = np.array([(list_ranges[R]["max"][0] * MAX_RANGE) + anchor["x"],
                                (list_ranges[R]["max"][1] * MAX_RANGE) + anchor["y"]])
                    # plt.scatter(x=[max_pose[0]], y=[max_pose[1]], c="b", marker="x", label="max")

                    if R == (len(list_ranges) - 1):
                        # plt.plot([anchor["x"], mean_pose[0]], [anchor["y"], mean_pose[1]], linestyle="dotted", c="g", label="mean_range" )
                        plt.plot([anchor["x"], min_pose[0]], [anchor["y"], min_pose[1]], linestyle="dotted", c="r", label="min_range")
                        plt.plot([anchor["x"], max_pose[0]], [anchor["y"], max_pose[1]], linestyle="dotted", c="b", label="MAX_RANGE")
                    else:
                        # plt.plot([anchor["x"], mean_pose[0]], [anchor["y"], mean_pose[1]], linestyle="dotted", c="g", )
                        plt.plot([anchor["x"], min_pose[0]], [anchor["y"], min_pose[1]], linestyle="dotted", c="r")
                        plt.plot([anchor["x"], max_pose[0]], [anchor["y"], max_pose[1]], linestyle="dotted", c="b")

                plt.legend()
                plt.axis("square")
                plt.show(block=False)

            return True

    else:

        try:
            anchor_1 = landmarks[anchor_candidates[0]]
            anchor_2 = landmarks[anchor_candidates[1]]
        except KeyError:
            # -- this anchor may instead be a waypoint in the Spot"s space:
            return False

        # NOTE: sometimes we may be evaluating the same anchor twice,
        #   so we need to check this before computing the relation:
        if anchor_candidates[0] == anchor_candidates[1]:
            return False

        if anchor_1["x"] == anchor_2["x"] and anchor_1["y"] == anchor_2["y"]:
            return False

        target = np.array([target["x"], target["y"]])
        anchor_1 = np.array([anchor_1["x"], anchor_1["y"]])
        anchor_2 = np.array([anchor_2["x"], anchor_2["y"]])

        # -- checking if something lies between two anchors is fairly simple: https://math.stackexchange.com/a/190373

        # -- computing vectors perpendicular to each anchoring point:
        vec_a1_to_a2 = anchor_2 - anchor_1; vec_a1_to_a2 /= np.linalg.norm(vec_a1_to_a2)
        vec_a2_to_a1 = anchor_1 - anchor_2; vec_a2_to_a1 /= np.linalg.norm(vec_a2_to_a1)
        A, B = rotate(vec_a1_to_a2 * MAX_RANGE, np.deg2rad(-90)) + anchor_1, rotate(vec_a1_to_a2 * MAX_RANGE, np.deg2rad(90)) + anchor_1
        C, D = rotate(vec_a2_to_a1 * MAX_RANGE, np.deg2rad(-90)) + anchor_2, rotate(vec_a2_to_a1 * MAX_RANGE, np.deg2rad(90)) + anchor_2

        dot_ABAM = np.dot(B-A, target-A)
        dot_ABAB = np.dot(B-A, B-A)
        dot_BCBM = np.dot(C-B, target-B)
        dot_BCBC = np.dot(C-B, C-B)

        if 0 <= dot_ABAM and dot_ABAM <= dot_ABAB and 0 <= dot_BCBM and dot_BCBM <= dot_BCBC:
            if plot:
                plt.figure()

                plt.scatter(x=[robot["x"]], y=[robot["y"]], marker="o", color="yellow", label="robot")
                plt.scatter(x=[target[0]], y=[target[1]], marker="o", color="green", label="target")
                plt.scatter(x=[anchor_1[0]], y=[anchor_1[1]], marker="o", color="orange", label="anchor")
                plt.scatter(x=[anchor_2[0]], y=[anchor_2[1]], marker="o", color="orange", label="anchor")

                plt.plot([A[0], anchor_1[0]], [A[1], anchor_1[1]], linestyle="dotted", c="r")
                plt.plot([C[0], anchor_2[0]], [C[1], anchor_2[1]], linestyle="dotted", c="b")
                plt.plot([B[0], anchor_1[0]], [B[1], anchor_1[1]], linestyle="dotted", c="r")
                plt.plot([D[0], anchor_2[0]], [D[1], anchor_2[1]], linestyle="dotted", c="b")

                plt.text(x=target[0], y=target[1], s=target_candidate)
                plt.text(x=anchor_1[0], y=anchor_1[1], s=anchor_candidates[0])
                plt.text(x=anchor_2[0], y=anchor_2[1], s=anchor_candidates[1])

                plt.title(f"Final Grounding: {sre}\n(Target:{target_candidate}, Anchor:{anchor_candidates})")
                plt.axis("square")
                plt.show(block=False)

            print(f"    - VALID LANDMARKS:\ttarget:{target_candidate}\tanchor:{anchor_candidates}")
            return True

        return False

    return False


def spg(landmarks, reg_out, topk):
    print(f"Command: {reg_out['utt']}\n")

    spg_output = {}

    for sre, grounded_spatial_preds in reg_out["grounded_sre_to_preds"].items():
        print(f"Grounding SRE: {sre}")

        rel_query, lmk_grounds = list(grounded_spatial_preds.items())[0]

        # Rank all combinations of target and anchor landmarks
        # TODO: currently pick topk combinations based on joint cosine similarity score
        # is there a better way to weigh both distance of target and the joint score?
        lmk_grounds_sorted = sort_combs(lmk_grounds)

        if rel_query == "None":
            # Referring expression without spatial relation
            groundings = [{"target": lmk_ground["target"][0]} for lmk_ground in lmk_grounds_sorted[:topk]]
        else:
            groundings = []

            rel_match = rel_query
            if rel_query not in KNOWN_RELATIONS:
                # Find best match for unseen spatial relation in set of known spatial relations
                rel_match = find_match_rel(rel_query)
                print(f"### UNSEEN SPATIAL RELATION:\t'{rel_query}' matched to '{rel_match}'")

            if len(lmk_grounds) == 1:
                # Spatial referring expression contains only a target landmark
                for lmk_ground in lmk_grounds_sorted[:topk]:
                    groundings.append(get_target_pos(landmarks, rel_match, lmk_ground["target"][0], sre))
            else:
                # Spatial referring expression contains a target landmark and one or two anchoring landmarks
                # one anchor, e.g., <tgt> left of <anc1>
                # two anchors, e.g., <tgt> between <anc1> and <anc2>
                for lmk_ground in lmk_grounds_sorted:
                    target_name = lmk_ground["target"][0]
                    anchor_names = lmk_ground["anchor"]
                    is_valid = eval_spatial_pred(landmarks, rel_match, target_name, anchor_names, sre=sre)
                    if is_valid:
                        groundings.append({"target": target_name,  "anchor": anchor_names})

                    if len(groundings) == topk:
                        break
        spg_output[sre] = groundings

        plt.close("all")
        print("\n\n")

    return spg_output


if __name__ == "__main__":
    location = "blackstone"
    data_dpath = os.path.join(os.path.expanduser("~"), "ground", "data")
    graph_dpath = os.path.join(data_dpath, "maps", "downloaded_graph_2024-01-27_07-48-53")
    osm_fpath = os.path.join(data_dpath, "osm", f"{location}.json")
    reg_outs_fpath = os.path.join(os.path.expanduser("~"), "ground", "results", f"reg_outs_{location}.json")

    reg_outputs = load_from_file(reg_outs_fpath)
    landmarks = load_lmks(graph_dpath, osm_fpath)
    for reg_output in reg_outputs:
        spg(landmarks, reg_output, topk=5)
